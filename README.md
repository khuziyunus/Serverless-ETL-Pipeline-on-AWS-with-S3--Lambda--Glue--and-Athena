# ğŸ› ï¸ AWS Serverless ETL Pipeline with S3, Glue & Athena

This project demonstrates how to build a fully serverless ETL (Extract, Transform, Load) data pipeline on AWS using S3, Glue, and Athena. It extracts raw CSV data uploaded to S3, transforms it using AWS Glue (written in PySpark), and queries the cleaned data with Athena.

---

## ğŸ“Œ Table of Contents

- [ğŸ¯ Objective](#-objective)
- [ğŸ§° Tools & Services Used](#-tools--services-used)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸš€ How It Works](#-how-it-works)
- [ğŸ§ª Sample Dataset](#-sample-dataset)
- [ğŸ“¸ Screenshots](#-screenshots)
- [ğŸ“Š Athena Query Result](#-athena-query-result)
- [ğŸ“ How to Run](#-how-to-run)
- [ğŸ“ˆ Future Improvements](#-future-improvements)

---

## ğŸ¯ Objective

To build a cost-efficient, scalable, and serverless data pipeline on AWS that:

- Accepts CSV files via Amazon S3.
- Cleans and transforms the data using AWS Glue with PySpark.
- Stores the transformed data in S3 as a single CSV.
- Enables querying and analysis using Amazon Athena.

---

## ğŸ§° Tools & Services Used

| Service         | Purpose                          |
|----------------|----------------------------------|
| **Amazon S3**   | Store raw and transformed data   |
| **AWS Glue**    | ETL pipeline using PySpark       |
| **AWS Athena**  | Query data using SQL             |
| **IAM**         | Access and permission control    |
| **CloudWatch**  | Logs and job monitoring          |
| **Python**      | Generate sample dataset          |

---

## ğŸ“ Project Structure

